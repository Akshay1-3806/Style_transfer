{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"name":"style_aware_fastai.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"id":"Kb_2dgk9hGDa"},"source":["from google.colab import drive       \n","drive.mount('/content/drive')         \n","# drive.mount(\"/content/drive\", force_remount=True)   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnGzspGNNmh-"},"source":["!pip install fastai==2.1.8                                  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"_qibgMe9i8x1","executionInfo":{"status":"ok","timestamp":1619169398259,"user_tz":-330,"elapsed":5028,"user":{"displayName":"Akshay tiwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn8ecAR1zDtc5t4Ux6eATphCew-Vf2GS9fdUQeQQ=s64","userId":"06308857780159687192"}},"outputId":"33eca6d4-191a-48bb-80ea-86481aa7132d"},"source":["import fastai                    \n","#export                             \n","from fastai.basics import *        \n","from fastai.callback.core import *          \n","from fastai.vision.all import *         \n","fastai.__version__                                "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.1.8'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Z4nL3Jrgi1w4"},"source":["## Wrapping the modules"]},{"cell_type":"markdown","metadata":{"id":"zhIdq2WBcwEQ"},"source":["### Second GANModule"]},{"cell_type":"code","metadata":{"id":"AJcL0jS4gaH9"},"source":["#export\n","class GANModule(Module):\n","    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n","    def __init__(self, generator=None, critic=None, gen_mode=False):\n","        if generator is not None: self.generator=generator\n","        if critic    is not None: self.critic   =critic        \n","        self.features = []\n","        self.input = []\n","        self.features_crit = []\n","        store_attr('gen_mode')\n","\n","    def SaveFeatures(self,unet):         \n","        for i,layer in enumerate(unet.children()):       \n","            for k,layer2 in enumerate(layer):\n","                for j,layer1 in enumerate(layer2.children()):   \n","                    if j==0:                                  \n","                        layer1.register_forward_hook(self.hook_fn1)\n","                    if j==5:                                 \n","                        layer1.register_forward_hook(self.hook_fn)\n","                        \n","\n","    def hook_fn(self,m,i,o): self.features.append(o)  # = o\n","    def hook_fn1(self,m,i,o): self.input.append(i)\n","\n","    def SaveCriticFeatures(self,unet):\n","      for j,layer1 in enumerate(unet.children()):    \n","        if j in (0,2,4,6):                   \n","          layer1.register_forward_hook(self.hook_fn_crit)\n","        \n","    def hook_fn_crit(self,m,i,o): self.features_crit.append(o)\n","\n","    def forward(self, *args): \n","        return self.generator(*args) if self.gen_mode else self.critic(*args)\n","\n","    def switch(self, gen_mode=None):\n","        \"Put the module in generator mode if `gen_mode`, in critic mode otherwise.\"\n","        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG4vtfc0IDaD"},"source":["## Creating the generator  "]},{"cell_type":"markdown","metadata":{"id":"Q1QobaxxMy2N"},"source":["### Code - 6"]},{"cell_type":"code","metadata":{"id":"hrPa4F-5M8Uo"},"source":["class deconv2d(nn.Module):\n","    \"\"\" Upsample block suggested by [2] to remove checkerboard pattern from images \"\"\"\n","    def __init__(self, input_, output_dim,ks=3,scale_factor_=2,use_cuda=False):\n","        super(deconv2d, self).__init__()\n","        if use_cuda:\n","            self.up1 = nn.UpsamplingNearest2d(scale_factor=scale_factor_).cuda(device_id=0)\n","            self.c2 = nn.Conv2d(input_, output_dim, kernel_size=3, stride=1, padding=0).cuda(device_id=0)\n","        else:\n","            self.up1 = nn.UpsamplingNearest2d(scale_factor=scale_factor_)\n","            self.c2 = nn.Conv2d(input_, output_dim, kernel_size=3, stride=1, padding=0)\n","            \n","    def forward(self, x):\n","        h = self.up1(x)\n","        h = F.pad(h, (1, 1, 1, 1), mode='reflect')\n","        h = (self.c2(h))\n","        return h\n","\n","\n","class res_block(nn.Module):\n","    def __init__(self,in_dim, out_dim, ks=3, s=1):\n","        super().__init__()\n","        self.in_dim,self.out_dim,self.ks,self.s = in_dim,out_dim,ks,s\n","        self.p = int((self.ks - 1) / 2)\n","        self.layers=nn.Sequential(*[nn.Conv2d(self.in_dim,self.out_dim,kernel_size=self.ks,stride=self.s,\n","                                              padding=0,bias=False),\n","                                    nn.InstanceNorm2d(num_features=out_dim,eps = 0.00001,affine=True,\n","                                                      momentum=0.05)]).cuda()\n","    def forward(self,x):\n","        y = F.pad(x,(self.p,self.p,self.p,self.p),mode='reflect').cuda()\n","        y = self.layers(y)\n","        y = F.relu(y)\n","        y = F.pad(y,(self.p,self.p,self.p,self.p),mode='reflect').cuda()\n","        y = self.layers(y)\n","        return x+y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vv5qqfAKNAre"},"source":["import torch.nn.functional as F\n","\n","discriminator_cfg_p16_D = {\n","\t'l_num': 4,'linear':256,\n","\t'l0_c': 3,                           # 256\n","\t'l1_ci': 256,'l1_cf': 256,   'l1_k': 3, 'l1_s': 2, # 64\n","\t'l2_ci': 256,'l2_cf': 128,   'l2_k': 3, 'l2_s': 2, # 64\n","\t'l3_ci': 128,'l3_cf': 64,   'l3_k': 3, 'l3_s': 2, # 64\n","\t'l4_ci': 64,'l4_cf': 32,   'l4_k': 3, 'l4_s': 2, # 16\n","}\n","\n","supported_patch_size_D = {\n","\t16: discriminator_cfg_p16_D\n","}\n","\n","discriminator_cfg_p16 = {\n","\t'l_num': 5,'linear':256,\n","\t'l0_c': 3,                           # 256\n","\t'l1_ci': 3,'l1_cf': 32,   'l1_k': 3, 'l1_s': 1, # 64\n","\t'l2_ci': 32,'l2_cf': 32,   'l2_k': 3, 'l2_s': 2, # 64\n","\t'l3_ci': 32,'l3_cf': 64,   'l3_k': 3, 'l3_s': 2, # 64\n","\t'l4_ci': 64,'l4_cf': 128,   'l4_k': 3, 'l4_s': 2, # 16\n","\t'l5_ci': 128,'l5_cf': 256,   'l5_k': 3, 'l5_s': 2, # 16\n","}\n","\n","supported_patch_size = {\n","\t16: discriminator_cfg_p16\n","}\n","\n","\n","class Decoder(nn.Module):\n","  def __init__(self):   # list_\n","    super(Decoder, self).__init__()\n","\n","    layers = []\n","    layers32 = []\n","    layers64 = []\n","    layers128 = []\n","    layers256 = []\n","    patch_size = 16\n","    cfg = supported_patch_size[patch_size]\n","    \n","    self.norm_ = nn.InstanceNorm2d(num_features=3,eps = 0.00001,affine=True,momentum=0.05)\n","    for l in range(1,cfg['l_num']+1): \n","      convo = {'l2_layer': layers32,'l3_layer': layers64,'l4_layer': layers128,'l5_layer': layers256}\n","      if l==2 or l==3 or l==4 or l==5:\n","        convo[f'l{l}_layer']+=(nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],\n","                                                         kernel_size=cfg[f'l{l}_k'],stride=cfg[f'l{l}_s'],\n","                                                         padding=0,bias=False),\n","                                               nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,\n","                                                                 affine=True,momentum=0.05),\n","                                               nn.ReLU()]))\n","      else:\n","        layers+=(nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],kernel_size=cfg[f'l{l}_k'],\n","                                           stride=cfg[f'l{l}_s'],padding=0,bias=False),\n","                                nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,affine=True,\n","                                                  momentum=0.05),\n","                                nn.ReLU()]))     \n","    self.layers = nn.Sequential(*layers)#.cuda()\n","    self.layers32 = nn.Sequential(*layers32)\n","    self.layers64 = nn.Sequential(*layers64)\n","    self.layers128 = nn.Sequential(*layers128)\n","    self.layers256 = nn.Sequential(*layers256)\n","\n","    layers1 = []\n","    layers3 = []\n","    layers4 = []\n","    patch_size = 16\n","    \n","    cfg = supported_patch_size_D[patch_size]\n","    \n","    for l in range(1,cfg['l_num']+1): \n","        convo = {'l3_layer': layers3,'l4_layer': layers4,}\n","        if l>=3:                        # concat starts from 128 and goes to 32\n","            convo[f'l{l}_layer'].append(nn.Conv2d(2*cfg[f'l{l}_ci'],cfg[f'l{l}_ci'],kernel_size=1,\n","                                                  stride=1,padding=0,bias=False)) \n","            convo[f'l{l}_layer'].append(deconv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],\n","                                                 ks=cfg[f'l{l}_k']))  \n","            convo[f'l{l}_layer'].append(nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,\n","                                                          affine=True,momentum=0.05))\n","            convo[f'l{l}_layer'].append(nn.ReLU())\n","        else:\n","            layers1.append(deconv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],ks=cfg[f'l{l}_k'],\n","                                    scale_factor_=cfg[f'l{l}_s']))  \n","            layers1.append(nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,\n","                                             affine=True,momentum=0.05))\n","            layers1.append(nn.ReLU())\n","    self.res_ = nn.Sequential(*[res_block(in_dim = 256,out_dim = 256) for _ in range(9)])                                \n","    self.layers_ = nn.Sequential(*layers1).cuda()\n","    self.last_conv_ = nn.Conv2d(64,3,kernel_size=7,stride=1,padding=0,bias=False).cuda() \n","    self.first_layer_cat = nn.Conv2d(6,3,kernel_size=1,stride=1,padding=0,bias=False)\n","    self.layers_3 = nn.Sequential(*layers3).cuda()\n","    self.layers_4 = nn.Sequential(*layers4).cuda()\n","\n","  def Interpolate(self, x,y):\n","    if y.shape[-2:] != x.shape[-2:]:\n","        x = F.interpolate(x, y.shape[-2:], mode='nearest')\n","    return x\n","  \n","  def forward(self, tensor_orig):\n","    x_tensor_orig = self.norm_(tensor_orig)\n","    x = F.pad(x_tensor_orig,(15,15,15,15),mode='reflect')\n","    x = self.layers(x)\n","    x32 = self.layers32(x)\n","    x64 = self.layers64(x32)\n","    x128 = self.layers128(x64)\n","    x = self.layers256(x128)\n","\n","    x = self.res_(x)\n","    x = self.layers_(x)\n","    list_2 = x128.detach() #\n","    x_cat = self.Interpolate(list_2,x) #\n","    x = torch.cat([x_cat,x],dim=1) #\n","    # x = x_cat+x\n","    x_ = self.layers_3(x)\n","    list_1 = x64.detach()\n","    x_cat = self.Interpolate(list_1,x_)\n","    x_ = torch.cat([x_cat,x_],dim=1)\n","    # x_ = x_cat+x_\n","    x__ = self.layers_4(x_)\n","    list_0 = x32.detach()\n","    x_cat = self.Interpolate(list_0,x__)\n","    x__ = torch.cat([x_cat,x__],dim=1)\n","    # x__ = x_cat+x__\n","    x = F.pad(x__,(3,3,3,3),mode='reflect')\n","    x = self.last_conv_(x)\n","    tensor_orig_ = tensor_orig.detach() #\n","    x = torch.cat([tensor_orig_,x],dim=1) #\n","    x = self.first_layer_cat(x) #\n","    x = nn.Sigmoid().cuda()(x)\n","    x = (x*2)-1\n","    return x "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDPH6xb9NFT2","executionInfo":{"status":"ok","timestamp":1619169402152,"user_tz":-330,"elapsed":8873,"user":{"displayName":"Akshay tiwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggn8ecAR1zDtc5t4Ux6eATphCew-Vf2GS9fdUQeQQ=s64","userId":"06308857780159687192"}},"outputId":"c017cad4-eb3d-4687-cf81-3c2056d9f294"},"source":["class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","    self.gen = nn.Sequential(Decoder()).cuda()\n","  def forward(self, x):\n","    fake_picture = self.gen(x)\n","    not_useful_output = self.gen(fake_picture)                \n","    return fake_picture\n","\n","\n","Gen = Generator().cuda()\n","x = (torch.randn(10,3,256,256)).cuda()\n","Gen(x).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 3, 256, 256])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"ty5Ys-2jWg_2"},"source":["## Creating Critic "]},{"cell_type":"markdown","metadata":{"id":"IOBWTUsGGlE4"},"source":["### Paper Critic"]},{"cell_type":"code","metadata":{"id":"pWFoSvVJGsQg"},"source":["class discriminator_(nn.Module):\n","    def __init__(self,Spectral=True):\n","        super(discriminator_, self).__init__()\n","        \n","        self.Spectral = Spectral\n","\n","        discriminator_cfg_p16 = {\n","            'l_num': 5,'linear':256,\n","            'l0_c': 3,                           # 256\n","            'l1_ci': 3,'l1_cf': 128,   'l1_k': 5, 'l1_s': 2, # 64\n","            'l2_ci': 128,'l2_cf': 256,   'l2_k': 5, 'l2_s': 2, # 64\n","            'l3_ci': 256,'l3_cf': 512,   'l3_k': 5, 'l3_s': 2, # 64\n","            'l4_ci': 512,'l4_cf': 1024,   'l4_k': 5, 'l4_s': 2, # 16\n","            'l5_ci': 512,'l5_cf': 512,   'l5_k': 5, 'l5_s': 2, # 16\n","            'l6_ci': 512,'l6_cf': 1024,   'l6_k': 5, 'l6_s': 2, # 16\n","            'l7_ci': 1024,'l7_cf': 1024,   'l7_k': 5, 'l7_s': 2, # 16\n","        }\n","\n","        supported_patch_size = {\n","            16: discriminator_cfg_p16\n","        }\n","\n","        patch_size = 16\n","        cfg = supported_patch_size[patch_size]\n","        \n","        l = 1\n","        if not self.Spectral:   \n","          self.h0 = nn.Sequential(*[nn.Conv2d(cfg[f'l1_ci'],cfg[f'l1_cf'],kernel_size=cfg[f'l1_k'],stride=cfg[f'l1_s'],padding=0,bias=False),\n","                              nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,affine=True,momentum=0.05),\n","                              nn.LeakyReLU(0.2)])\n","        else: \n","          self.h0 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(cfg[f'l1_ci'],cfg[f'l1_cf'],kernel_size=cfg[f'l1_k'],stride=cfg[f'l1_s'],padding=0,bias=False)),\n","                              nn.LeakyReLU(0.2)])\n","        self.h0_pred = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_cf'],1,kernel_size=3,stride=1,padding=0,bias=False)])\n","\n","        l = 2\n","        if not self.Spectral:\n","          self.h1 = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],kernel_size=cfg[f'l{l}_k'],stride=cfg[f'l{l}_s'],padding=0,bias=False),\n","                              nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,affine=True,momentum=0.05),\n","                              nn.LeakyReLU(0.2)])\n","        else:\n","          self.h1 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(cfg[f'l2_ci'],cfg[f'l2_cf'],kernel_size=cfg[f'l2_k'],stride=cfg[f'l2_s'],padding=0,bias=False)),\n","                              nn.LeakyReLU(0.2)])\n","        self.h1_pred = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_cf'],1,kernel_size=5,stride=1,padding=0,bias=False)])\n","\n","        l = 3\n","        if not self.Spectral:\n","          self.h2 = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],kernel_size=cfg[f'l{l}_k'],stride=cfg[f'l{l}_s'],padding=0,bias=False),\n","                              nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,affine=True,momentum=0.05),\n","                              nn.LeakyReLU(0.2)])\n","        else:\n","          self.h2 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(cfg[f'l3_ci'],cfg[f'l3_cf'],kernel_size=cfg[f'l3_k'],stride=cfg[f'l3_s'],padding=0,bias=False)),\n","                              nn.LeakyReLU(0.2)])\n","        self.h2_pred = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_cf'],1,kernel_size=5,stride=1,padding=0,bias=False)])\n","\n","        l = 4\n","        if not self.Spectral:\n","          self.h3 = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_ci'],cfg[f'l{l}_cf'],kernel_size=cfg[f'l{l}_k'],stride=cfg[f'l{l}_s'],padding=0,bias=False),\n","                              nn.InstanceNorm2d(num_features=cfg[f'l{l}_cf'],eps = 0.00001,affine=True,momentum=0.05),\n","                              nn.LeakyReLU(0.2)])\n","        else:\n","          self.h3 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(cfg[f'l4_ci'],cfg[f'l4_cf'],kernel_size=cfg[f'l4_k'],stride=cfg[f'l4_s'],padding=0,bias=False)),\n","                              nn.LeakyReLU(0.2)])\n","        self.h3_pred = nn.Sequential(*[nn.Conv2d(cfg[f'l{l}_cf'],1,kernel_size=2,stride=1,padding=0,bias=False)])\n","\n","        self.avg = nn.AdaptiveAvgPool2d((1,1))    \n","        self.lrelu = nn.LeakyReLU(0.2)\n","    \n","    def shape_(self,x,s,k):\n","        shape = x.shape[2]\n","        shape = int((((s*(shape-1))+k)-shape)/2)\n","        # shape = int((shape+2)/2)\n","        return shape \n","\n","    def forward(self,x):\n","        x_h0 = self.h0(x)\n","        shape = self.shape_(x_h0,1,3)\n","        x_h0_ = F.pad(x_h0,(shape,shape,shape,shape),mode='reflect')\n","        h0_pred = self.h0_pred(x_h0_)\n","        # h0_pred = self.lrelu(h0_pred)\n","        h0_pred = self.avg(h0_pred)\n","\n","        x_h1 = self.h1(x_h0)\n","        shape = self.shape_(x_h1,1,5)\n","        x_h1_ = F.pad(x_h1,(shape,shape,shape,shape),mode='reflect')\n","        h1_pred = self.h1_pred(x_h1_)\n","        # h1_pred = self.lrelu(h1_pred)\n","        h1_pred = self.avg(h1_pred)\n","\n","        x_h2 = self.h2(x_h1)\n","        shape = self.shape_(x_h2,1,5) \n","        x_h2_ = F.pad(x_h2,(shape,shape,shape,shape),mode='reflect')\n","        h2_pred = self.h2_pred(x_h2_)\n","        # h2_pred = self.lrelu(h2_pred)\n","        h2_pred = self.avg(h2_pred)\n","        \n","        x_h3 = self.h3(x_h2)\n","        shape = self.shape_(x_h3,1,2) \n","        x_h3_ = F.pad(x_h3,(shape,shape,shape,shape),mode='reflect')\n","        h3_pred = self.h3_pred(x_h3_)\n","        # h3_pred = self.lrelu(h3_pred)\n","        final = self.avg(h3_pred)\n","        \n","        return h0_pred,h1_pred,h2_pred,final"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTnaEs57-ccH"},"source":["## Initiating generator and critic"]},{"cell_type":"code","metadata":{"id":"wGWLxTtXITsc"},"source":["from fastai.vision.models import resnet18\n","import torch.nn as nn\n","m = resnet18() \n","m = nn.Sequential(*list(m.children())[:-2]) \n","generator = Gen \n","critic = discriminator_(Spectral=False) \n","critic "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gijr5f7JXvGe"},"source":["res_input = nn.AvgPool2d(10, stride=1, padding=4, count_include_pad=False).cuda()\n","res_output = nn.AvgPool2d(10, stride=1, padding=4, count_include_pad=False).cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jUKwPcwX4iy"},"source":["## Loss function"]},{"cell_type":"code","metadata":{"id":"zOSvRUHWO_eV"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#export\n","class GANLoss(GANModule):\n","    \"Wrapper around `crit_loss_func` and `gen_loss_func`\"\n","    def __init__(self, gen_loss_func, crit_loss_func, gan_model):\n","        super().__init__()\n","        self.SaveFeatures(generator)\n","        self.SaveCriticFeatures(critic)\n","        store_attr('gen_loss_func,crit_loss_func,gan_model')\n","\n","    def gram(self,input_1):\n","        b,c,h,w = input_1.size()\n","        x = input_1.view(b,c, -1)\n","        return torch.bmm(x, x.transpose(1,2))/(b*c*h*w)*1e6\n","\n","    def gram_loss(self,input_, target):\n","        if self.gram(target).shape[0]!=16 or self.gram(input_).shape[0]!=16:\n","          m = min(self.gram(target).shape[0],self.gram(input_).shape[0])\n","          o,i = self.gram(target)[:m+1],self.gram(input_)[:m+1]\n","          return F.mse_loss(i,o)\n","        else:\n","          return F.mse_loss(self.gram(input_), self.gram(target))\n","\n","    def generator(self, output, target):\n","        \"Evaluate the `output` with the critic then uses `self.gen_loss_func`\"\n","        input_list = self.input  \n","        if (target).shape[0]!=16:\n","          pass \n","          \n","        fake_pred = self.gan_model.critic(output)\n","        fake = self.features_crit\n","        self.features_crit = []\n","        real_pred_ = self.gan_model.critic(target)\n","        real = self.features_crit       \n","        main_loss = 0\n","        for j,(inp,targ) in enumerate(zip(real, fake)):\n","          if j>0:\n","            main_loss += self.gram_loss(inp,targ)\n","\n","        style = 0.1; content = 100.0; aware = 100.0; gatey = 0.0 \n","        gen_loss = (self.gen_loss_func(fake_pred, output, target)) \n","        style_aware = self.features     \n","        x = style_aware[0]\n","        y = style_aware[1] #.detach()   \n","        input_ = res_input(input_list[0][0])\n","        target_ = res_output(output) \n","        \n","        style_aware_loss1 = F.mse_loss(input_,target_)\n","        style_aware_loss = F.mse_loss(x,y)\n","        self.gen_loss = (style*gen_loss)+(content*style_aware_loss1)+(aware*style_aware_loss)+gatey*main_loss  # gen_loss+  # (0.5*style_aware_loss1) reduced to half \n","        \n","        weights = [style ,content ,aware ,gatey]\n","        losses__ = [gen_loss,style_aware_loss1,style_aware_loss,main_loss]\n","        name = ['style_loss','content_loss','style_aware_loss','style_loss_perceptual']\n","\n","        for c,d,e in zip(weights,losses__,name):\n","          if c==0:\n","            print(1*d,f'{e}')\n","          else:\n","            print(c*d,f'{e}')\n","\n","\n","        self.check = 0\n","        self.features = []\n","        self.hook_layers = []  \n","        self.input = []\n","        self.features_crit = []\n","        return self.gen_loss \n","\n","    def critic(self, real_pred, input):\n","        \"Create some `fake_pred` with the generator from `input` and compare them to `real_pred` in `self.crit_loss_func`.\"\n","        fake = self.gan_model.generator(input) #.requires_grad_(False)\n","        fake_pred = self.gan_model.critic(fake)\n","        self.crit_loss = 1*(self.crit_loss_func(real_pred, fake_pred))  \n","        print(self.crit_loss,'critic_loss')\n","        self.check = 0\n","        self.features = []\n","        self.hook_layers = []\n","        self.input = []\n","        self.features_crit = []\n","        return self.crit_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-Fllj64i1xi"},"source":["## Callbacks for GAN training"]},{"cell_type":"markdown","metadata":{"id":"cwH0x8LScUWV"},"source":["### Main callback"]},{"cell_type":"code","metadata":{"id":"giAHmx0ni1xj"},"source":["#export \n","def set_freeze_model(m, rg): \n","    for p in m.parameters(): p.requires_grad_(rg) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnXhZjBD3Lsj"},"source":["class SiameseImage(fastuple):\n","    def show(self, title,ax=None,ctx=None, **kwargs): \n","        img1,_ = self\n","        return show_image(img1, ax=ax,title=title, ctx=ctx, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bG-q-bV6jZAP"},"source":["#export\n","prediction = []\n","from IPython.display import clear_output\n","\n","class GANTrainer(Callback):\n","    \"Handles GAN Training.\"\n","    run_after = TrainEvalCallback\n","    def __init__(self, switch_eval=False, clip=None, beta=0.98, gen_first=False, show_img=True,gen_lr =None ,critic_lr =None):\n","        store_attr('switch_eval,clip,gen_first,show_img')\n","        self.gen_loss,self.crit_loss = AvgSmoothLoss(beta=beta),AvgSmoothLoss(beta=beta)\n","        self.gen_lr_,self.critic_lr_ = gen_lr,critic_lr\n","        self.gen_lr_1,self.critic_lr_1 = gen_lr,critic_lr \n","\n","    def _set_trainable(self):\n","        train_model = self.generator if     self.gen_mode else self.critic\n","        loss_model  = self.generator if not self.gen_mode else self.critic\n","        set_freeze_model(train_model, True)\n","        set_freeze_model(loss_model, False)\n","        if self.switch_eval:\n","            train_model.train()\n","            loss_model.eval()\n","\n","    def before_fit(self):\n","        \"Initialize smootheners.\"\n","        self.generator,self.critic = self.model.generator,self.model.critic\n","        self.gen_mode = self.gen_first\n","        self.switch(self.gen_mode)\n","        self.crit_losses,self.gen_losses = [],[]\n","        self.gen_loss.reset() ; self.crit_loss.reset()\n","        self.mbar = master_bar(list(range(self.n_epoch))) ###\n","\n","    def before_validate(self):\n","        \"Switch in generator mode for showing results.\"\n","        self.switch(gen_mode=True)\n","\n","    def before_batch(self):\n","        \"Clamp the weights with `self.clip` if it's not None, set the correct input/target.\"\n","        if self.training and self.clip is not None:\n","            for p in self.critic.parameters(): p.data.clamp_(-self.clip, self.clip)\n","        if not self.gen_mode:\n","            (self.learn.xb,self.learn.yb) = (self.yb,self.xb)        \n","        if self.epoch>=0:\n","            if not self.learn.gan_trainer.gen_mode:\n","                self.learn.opt.set_hyper('lr', self.critic_lr_1)\n","                print(self.learn.opt.hypers[0]['lr'],'learning_rate_crit_not')\n","            if self.learn.gan_trainer.gen_mode:\n","                self.learn.opt.set_hyper('lr', self.gen_lr_1)\n","                print(self.learn.opt.hypers[0]['lr'],'learning_rate_gen_not')\n","        \n","    def after_batch(self):\n","        \"Record `last_loss` in the proper list.\"\n","        if not self.training: return\n","        if self.gen_mode:\n","            self.gen_loss.accumulate(self.learn)\n","            self.gen_losses.append(self.gen_loss.value)\n","\n","            self.last_gen = to_detach(self.pred)\n","            self.last_gen_ = to_detach(self.xb)\n","            img_ = self.last_gen[0]\n","            img_xb = self.last_gen_[0]\n","            self.learn.model.cuda()\n","            img2 = SiameseImage(img_,'kjkjj')    \n","            img = [img2] \n","            similarity = ['gjgj']\n","            self.mbar.show_imgs(img, similarity)\n","        else:\n","            self.crit_loss.accumulate(self.learn)\n","            self.crit_losses.append(self.crit_loss.value)\n","            self.learn.model.cuda()\n","            \n","    def before_epoch(self):\n","        \"Put the critic or the generator back to eval if necessary.\"\n","        self.switch(self.gen_mode)\n","        self.mbar.update(self.epoch)\n","\n","\n","    def after_epoch(self):\n","        clear_output(wait=True)\n","    \n","    def switch(self, gen_mode=None):\n","        \"Switch the model and loss function, if `gen_mode` is provided, in the desired mode.\"\n","        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n","        self._set_trainable()\n","        self.model.switch(gen_mode)\n","        self.loss_func.switch(gen_mode)    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rURzW0ddcKUh"},"source":["### Switchers"]},{"cell_type":"code","metadata":{"id":"Ok2kPV55i1xq"},"source":["# #export\n","class FixedGANSwitcher(Callback):\n","    \"Switcher to do `n_crit` iterations of the critic then `n_gen` iterations of the generator.\"\n","    run_after = GANTrainer\n","    def __init__(self, n_crit=1, n_gen=1): store_attr('n_crit,n_gen')\n","    def before_train(self): self.n_c,self.n_g = 0,0\n","\n","    def after_batch(self):\n","        \"Switch the model if necessary.\"\n","        if not self.training: return\n","        if self.learn.gan_trainer.gen_mode:\n","            self.n_g += 1\n","            n_iter,n_in,n_out = self.n_gen,self.n_c,self.n_g\n","        else:\n","            self.n_c += 1\n","            n_iter,n_in,n_out = self.n_crit,self.n_g,self.n_c\n","        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n","        if target == n_out:\n","            self.learn.gan_trainer.switch()\n","            self.n_c,self.n_g = 0,0 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"On6jB93rgGeV"},"source":["## GAN data for art"]},{"cell_type":"markdown","metadata":{"id":"d9gcoLL3yoQu"},"source":["### Dataloader "]},{"cell_type":"code","metadata":{"id":"KeWtePXB0oWV"},"source":["import numpy as np\n","import random\n","\n","list_ = []\n","def num_list():\n","  for t in range(0,29):     \n","    list_.append(t)\n","  return \n","\n","num_list()\n","\n","def output_pictures(t):   \n","    num = random.choice(list_)\n","    list_.remove(num)\n","    if len(list_)==0:\n","      num_list()\n","    path = '/content/drive/My Drive/Colab_Notebooks/Style_transfer/Style_aware_content_loss/painting_1/' # painting_1\n","    path_ = path+f'{num}.jpg'\n","    return path_  \n","\n","bs = 16 \n","size = 256  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1uPohbOndo2_"},"source":["### Datablock"]},{"cell_type":"code","metadata":{"id":"nWWQQjuL07N_"},"source":["dblock = DataBlock(blocks=(ImageBlock,ImageBlock),   \n","          get_y=output_pictures,\n","          get_items= get_image_files,\n","          splitter = RandomSplitter(),\n","          batch_tfms = [ Brightness(p=0.2, draw=[0.5, 0.55, 0.6, 0.7,0.5, 0.55, 0.6, 0.7,0.5, 0.55, 0.6, 0.7,0.5, 0.55, 0.6, 0.7]),\n","                        Saturation(max_lighting=0.2, p=0.2)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LP44Br51Wv8"},"source":["from pathlib import Path   \n","path = Path('/content/drive/My Drive/Colab_Notebooks/Style_transfer/Style_aware_content_loss/input_/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUPQUxvi1OaR"},"source":["dls = dblock.dataloaders(path,path=path,bs = bs,num_workers=0)     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xGT28nfqi1yE"},"source":["## GAN Learner"]},{"cell_type":"markdown","metadata":{"id":"PiozPPxIuEOe"},"source":["## Loss Function"]},{"cell_type":"code","metadata":{"id":"HZcLpcgH_QRt"},"source":["def _tk_mean(fake_pred, output, target): # gen_loss\n","  fake_pred_ = 0\n","  for x in fake_pred:\n","    target = torch.ones_like(x)\n","    h_ = torch.mean((torch.abs(x-target)))\n","    fake_pred_ += h_\n","  return fake_pred_\n","def _tk_diff(real_pred, fake_pred):     # crit_loss\n","  fake_pred_ = 0\n","  for x in fake_pred:\n","    target = torch.zeros_like(x)\n","    h_ = torch.mean((torch.abs(x-target)))\n","    fake_pred_ += h_\n","  \n","  real_pred_ = 0\n","  for y in real_pred:\n","    target = torch.ones_like(y)\n","    h_ = torch.mean((torch.abs(y-target)))\n","    real_pred_ += h_\n","  return fake_pred_+real_pred_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ICr37oYN6NsR"},"source":["## Training class"]},{"cell_type":"code","metadata":{"id":"B1_9m1u2i1yI"},"source":["#export\n","@delegates()\n","class GANLearner(Learner):\n","    \"A `Learner` suitable for GANs.\"\n","    def __init__(self, dls, generator, critic, gen_loss_func, crit_loss_func, switcher=None, gen_first=False,\n","                 switch_eval=True, show_img=True, clip=None, cbs=None, metrics=None, **kwargs):\n","        gan = GANModule(generator, critic)\n","        loss_func = GANLoss(gen_loss_func, crit_loss_func, gan)\n","        if switcher is None: switcher = FixedGANSwitcher(n_crit=2, n_gen=3) \n","        trainer = GANTrainer(clip=clip, switch_eval=switch_eval, gen_first=gen_first,\n","                             show_img=show_img,gen_lr = 2e-5,critic_lr = 2e-5) \n","        self.mode = gan.gen_mode \n","        cbs = L(cbs) + L(trainer, switcher)\n","        metrics = L(metrics) + L(*LossMetrics('gen_loss,crit_loss'))\n","        super().__init__(dls, gan, loss_func=loss_func, cbs=cbs, metrics=metrics, **kwargs)\n","\n","    @classmethod\n","    def from_learners(cls, gen_learn, crit_learn, switcher=None, weights_gen=None, **kwargs):\n","        \"Create a GAN from `learn_gen` and `learn_crit`.\"\n","        losses = gan_loss_from_func(gen_learn.loss_func, crit_learn.loss_func, weights_gen=weights_gen)\n","        return cls(gen_learn.dls, gen_learn.model, crit_learn.model, *losses, switcher=switcher, **kwargs)\n","\n","    @classmethod\n","    def wgan(cls, dls, generator, critic, switcher=None, clip=None, switch_eval=False, **kwargs):   # Clip=0.01\n","        \"Create a WGAN from `data`, `generator` and `critic`.\"\n","        return cls(dls, generator, critic, _tk_mean, _tk_diff, switcher=switcher, clip=clip, switch_eval=switch_eval, **kwargs)\n","    \n","GANLearner.from_learners = delegates(to=GANLearner.__init__)(GANLearner.from_learners)   \n","GANLearner.wgan = delegates(to=GANLearner.__init__)(GANLearner.wgan)   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OC4cmG_r8Fu0"},"source":["## Training\n","\n"]},{"cell_type":"code","metadata":{"id":"JLQbEmDTi1yP"},"source":["learn = GANLearner.wgan(dls, generator, critic, opt_func = Adam)\n","# gan_ = 'path/where/your/model/is/saved'   \n","# learn.load(gan_,with_opt=True)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEHh75gazJ04"},"source":["learn.model.cuda()  \n","clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"re31osmwi1yR"},"source":["learn.recorder.train_metrics=True    \n","learn.recorder.valid_metrics=True "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODrvW5ZvNEqd"},"source":["learn.fit(50, 0.01, wd=0)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xkj9e6rKSiyU"},"source":["gan_ = 'path/to/the/place/where/you/wnat/to/save/your/model'\n","learn.save(gan_,with_opt=True, pickle_protocol=2)                         "],"execution_count":null,"outputs":[]}]}